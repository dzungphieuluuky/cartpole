# ğŸ† RL Agent for CartPole-v1

## ğŸ¯ Overview
This project implements a **Reinforcement Learning (DRL) agent** using **Cross-entropy method** to solve **CartPole-v1** from Gymnasium.

The goal of the agent is to balance the pole as long as possible. A termination state occurs when the pole is displaced from the vertical line at a certain angle.

## ğŸš€ Key Feature
- Train using Cross-entropy methods.
- Using prioritized mini batches with rewards at 70% percentile.
- Feed forward neural network.

## ğŸ–ï¸ Architecture
- Environment: CartPole-v1.
- Loss function: Cross Entropy Loss.
- Network: Feed Forward Neural Network.
- Optimizer: Adam.
- Prioritized mini batches.

## ğŸŒ¹ Dependencies (Windows)
```bash=
pip install -r requirements.txt
```

## ğŸ¼ References
**Deep Reinforcement Learning Hands-On** by Maxim Lapan.

## ğŸ§ Usage
- Run `train.py` to train the agent.
- Results will automatically be saved in `results.npy`.
- Model file is saved in `model` folder.
- Run `play.py` to watch the agent play.
- Run `plot_results.py` to watch the training progress graph.
